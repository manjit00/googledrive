{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxT/cRY8qggEXXDUWlpAub"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KMS05B1ubSHL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733172259014,"user_tz":300,"elapsed":31713,"user":{"displayName":"Manjit Singh","userId":"04641024576264730749"}},"outputId":"87493b98-baa6-42ad-aa4a-d3ff6d324c9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n","Mounted at /content/drive\n","\n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","65\n","This is Manjit\n"]}],"source":["import torch\n","from math import log\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","batch_size = 32\n","block_size = 8\n","max_iters = 3000\n","eval_interval = 300\n","learning_rate=1e-3\n","eval_iters = 200\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print (device)\n","\n","from google.colab import drive\n","drive.mount ('/content/drive')\n","\n","with open('/content/drive/My Drive/Colab Notebooks/input.txt', 'r', encoding='utf-8') as f:\n","  text = f.read()\n","\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(''.join(chars))\n","print (vocab_size)\n","\n","# tokenize convert text to sequence of integers\n","stoi = {ch: i for i, ch in enumerate(chars)}\n","itos = {i: ch for i, ch in enumerate(chars)}\n","\n","encode = lambda s: [stoi[c] for c in s]\n","decode = lambda l: ''.join([itos[i] for i in l])\n","\n","#print (encode(\"This is Manjit\"))\n","print (decode(encode(\"This is Manjit\")))\n","\n","data = torch.tensor(encode(text), dtype = torch.long)\n","\n","n = int(0.9 * len(data)) # 90% train, 10% test (validation data)\n","train_data = data[:n] # train data\n","val_data = data[n:] # validation data\n","\n","block_size = 8\n","train_data[:block_size + 1]\n","\n","x = train_data[:block_size]\n","y = train_data[1:block_size + 1]\n","for t in range(block_size):\n","    context = x[:t + 1]\n","    target = y[t]\n","    #print(f'when input is {context}, the target: {target}')\n","\n","torch.manual_seed(1337)\n","\n","\n","def get_batch(split):\n","    data = train_data if split == 'train' else val_data\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x = torch.stack([data[i:i + block_size] for i in ix])\n","    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n","    x, y = x.to(device), y.to(device)\n","\n","    return x, y\n","\n","xb, yb = get_batch('train')\n","#print('inputs:')\n","#print (xb.shape)\n","#print(xb)\n","#print('targets:')\n","#print(yb.shape)\n","#print(yb)\n","\n","\n","for b in range(batch_size):\n","    for t in range(block_size):\n","        context = xb[b, :t + 1]\n","        target = yb[b, t]\n","        #print(f'when input is {context.tolist()}, the target: {target}')\n","\n"]},{"cell_type":"code","source":["\n","\n","class BigramLanguageModel(nn.Module):\n","\n","    def __init__(self, vocab_size):\n","        super().__init__()\n","        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","        logits = self.token_embedding_table(idx) # (B,T,C)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","        return logits, loss\n","\n","    def generate(self,idx,max_new_tokens):\n","        for _ in range(int(max_new_tokens)):\n","            logits, loss = self(idx)\n","            #logits = logits[0]\n","            logits = logits[:,-1,:]\n","            probs = F.softmax(logits, dim=-1)\n","            idx_next = torch.multinomial(probs, num_samples=1)\n","            idx = torch.cat((idx, idx_next), dim=1)\n","        return idx\n","\n","model = BigramLanguageModel(vocab_size)\n","m = model.to(device)\n","\n","@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_batch(split)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","for iter in range(max_iters):\n","\n","  if iter % eval_interval == 0:\n","    losses = estimate_loss()\n","    print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","  xb, yb = get_batch('train')\n","  logits, loss = m(xb, yb)\n","  optimizer.zero_grad(set_to_none=True)\n","  loss.backward()\n","  optimizer.step()\n","\n","print(loss.item())\n","context = torch.zeros((1,1), dtype=torch.long, device=device)\n","print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n","\n","\n","1:02:46\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"qGntI9WttPyN","executionInfo":{"status":"error","timestamp":1733172313896,"user_tz":300,"elapsed":354,"user":{"displayName":"Manjit Singh","userId":"04641024576264730749"}},"outputId":"b457de0c-2b25-4c8d-abf6-25d5381edc41"},"execution_count":1,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<ipython-input-1-7dd98bdf351e>, line 65)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-7dd98bdf351e>\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    1:02:46\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"]}]},{"cell_type":"code","source":["\n","B,T,C=4,8,32\n","x = torch.randn(B,T,C)\n","print(x)\n"],"metadata":{"id":"FvzER1KmsxDG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732722761378,"user_tz":300,"elapsed":85,"user":{"displayName":"Manjit Singh","userId":"04641024576264730749"}},"outputId":"75ec3cef-0b6e-4884-c2da-d9760d3d573a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[-1.4687, -0.1518,  0.7498,  ...,  2.3512, -1.3086, -0.3565],\n","         [ 0.8805, -0.0164,  0.3737,  ..., -1.1304,  0.2162, -0.8482],\n","         [ 0.2896, -0.0938, -0.6820,  ...,  0.4895,  0.0872, -1.3640],\n","         ...,\n","         [-1.2517,  0.6726, -1.2619,  ..., -1.0056,  0.7523, -0.6185],\n","         [ 1.2602, -0.2122, -1.0709,  ...,  0.2736, -0.1919, -0.6448],\n","         [-0.3180,  2.1918,  0.6352,  ..., -0.1756, -0.7506,  0.8345]],\n","\n","        [[-0.3092,  1.8413,  2.0893,  ..., -0.5337, -0.6754, -0.7354],\n","         [-0.5941,  0.5434,  0.5130,  ...,  0.4598,  0.2554, -0.9636],\n","         [-1.2100, -1.5967,  0.4598,  ..., -0.6975, -0.9933,  0.4394],\n","         ...,\n","         [-1.7886,  0.7822,  1.5901,  ...,  1.0275, -0.2810, -1.1213],\n","         [-0.5666,  1.3122, -0.1253,  ..., -0.3216, -1.1370, -0.5281],\n","         [ 0.2275, -0.4873,  0.0369,  ..., -1.8277,  1.6686,  0.1663]],\n","\n","        [[ 1.7751, -0.1566,  1.0223,  ..., -1.0404, -1.3350,  0.1033],\n","         [-0.0818, -1.5029,  0.9906,  ...,  0.9494, -0.1396,  1.0830],\n","         [ 1.7344, -0.7087,  0.9001,  ..., -0.9142, -0.7035,  0.8168],\n","         ...,\n","         [-0.6279,  1.7224,  0.9682,  ...,  0.3249,  1.4141,  0.1671],\n","         [-1.7448,  0.3334, -0.2341,  ...,  0.6941, -0.4666,  0.1352],\n","         [ 0.6473,  0.9818,  0.6464,  ..., -0.5197,  0.7299, -0.3126]],\n","\n","        [[-0.0544,  0.7757, -2.0235,  ...,  0.2943, -1.4079,  0.9682],\n","         [ 0.0052, -0.2442, -0.5874,  ..., -0.3667, -0.0906,  0.3418],\n","         [-0.5505, -0.2396,  0.7247,  ...,  0.0637,  0.3648,  0.9969],\n","         ...,\n","         [-0.7802,  0.2299,  0.7059,  ...,  0.3151,  1.0310, -0.2636],\n","         [-0.5882, -1.6778,  0.4542,  ..., -1.0952,  0.0579,  0.2227],\n","         [ 0.7998, -0.4821,  2.3368,  ..., -0.0930, -0.5683, -1.9056]]])\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"6RYfg9kwcUON"}}]}